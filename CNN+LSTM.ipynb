{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as HouseB_merged.csv\n",
      "Training and testing separated successfully\n",
      "Preprocessing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Chubaasiny Eswararao\n",
    "# Date: 3rd December 2024\n",
    "# Title : Inventory and Sales Management System for Retail Shop\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set the directory containing the CSV files\n",
    "directory = r\"C:\\Users\\chuba\\Desktop\\AI\\CSV_format (ARAS A, ARAS B)\\CSV_format (ARAS A, ARAS B)\\House B\"\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Sort files to ensure the order (Day1-Day30)\n",
    "csv_files.sort()\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Read each file and append to the list\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    # Specify space as the delimiter and no header since columns are not named\n",
    "    df = pd.read_csv(file_path, sep='\\s+', header=None)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged dataframe to a new CSV\n",
    "merged_df.to_csv(\"HouseB_merged.csv\", index=False, header=False)\n",
    "print(\"Merged dataset saved as HouseB_merged.csv\")\n",
    "\n",
    "# Split into training and testing sets (24 days for training, 6 days for testing)\n",
    "train_days = 24 * 86400  \n",
    "train_df = merged_df.iloc[:train_days]\n",
    "test_df = merged_df.iloc[train_days:]\n",
    "print(\"Training and testing separated successfully\")\n",
    "\n",
    "# Separate features (sensor data) and labels\n",
    "X_train = train_df.iloc[:, :-2].values  # All columns except last two (sensor data)\n",
    "y_train_res1 = train_df.iloc[:, -2].values  # Second last column is activity label for resident 1\n",
    "y_train_res2 = train_df.iloc[:, -1].values  # Last column is activity label for resident 2\n",
    "\n",
    "X_test = test_df.iloc[:, :-2].values\n",
    "y_test_res1 = test_df.iloc[:, -2].values\n",
    "y_test_res2 = test_df.iloc[:, -1].values\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on training data and transform both\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for CNN + LSTM model\n",
    "# CNN expects (samples, height, width) - 3D input\n",
    "# LSTM expects (samples, timesteps, features) - 3D input\n",
    "\n",
    "# Reshape for CNN input (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))  # 1 feature per timestep\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Reshape for LSTM input (samples, timesteps, features)\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], 20, 1))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], 20, 1))\n",
    "\n",
    "# One-hot encode the activity labels (for both residents)\n",
    "y_train_res1 = to_categorical(y_train_res1 - 1, num_classes=27)  # Adjusting for 0-indexed classes\n",
    "y_test_res1 = to_categorical(y_test_res1 - 1, num_classes=27)\n",
    "\n",
    "y_train_res2 = to_categorical(y_train_res2 - 1, num_classes=27)\n",
    "y_test_res2 = to_categorical(y_test_res2 - 1, num_classes=27)\n",
    "\n",
    "print(\"Preprocessing completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,800</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,100</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resident1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,727</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resident2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,727</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)        │     \u001b[38;5;34m37,800\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │      \u001b[38;5;34m7,100\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resident1 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │      \u001b[38;5;34m2,727\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resident2 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │      \u001b[38;5;34m2,727\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,610</span> (197.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,610\u001b[0m (197.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,610</span> (197.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,610\u001b[0m (197.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 9ms/step - loss: 0.6654 - resident1_accuracy: 0.9006 - resident1_loss: 0.2174 - resident2_accuracy: 0.8948 - resident2_loss: 0.4018 - val_loss: 0.5532 - val_resident1_accuracy: 0.9418 - val_resident1_loss: 0.1416 - val_resident2_accuracy: 0.9395 - val_resident2_loss: 0.3992\n",
      "Epoch 2/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 7ms/step - loss: 0.5483 - resident1_accuracy: 0.9153 - resident1_loss: 0.1839 - resident2_accuracy: 0.9057 - resident2_loss: 0.3528 - val_loss: 0.5536 - val_resident1_accuracy: 0.9429 - val_resident1_loss: 0.1459 - val_resident2_accuracy: 0.9343 - val_resident2_loss: 0.3976\n",
      "Epoch 3/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 7ms/step - loss: 0.5421 - resident1_accuracy: 0.9155 - resident1_loss: 0.1823 - resident2_accuracy: 0.9059 - resident2_loss: 0.3500 - val_loss: 0.5560 - val_resident1_accuracy: 0.9426 - val_resident1_loss: 0.1442 - val_resident2_accuracy: 0.9329 - val_resident2_loss: 0.4023\n",
      "Epoch 4/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 8ms/step - loss: 0.5402 - resident1_accuracy: 0.9155 - resident1_loss: 0.1821 - resident2_accuracy: 0.9061 - resident2_loss: 0.3494 - val_loss: 0.5630 - val_resident1_accuracy: 0.9318 - val_resident1_loss: 0.1527 - val_resident2_accuracy: 0.9344 - val_resident2_loss: 0.4019\n",
      "Epoch 5/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 7ms/step - loss: 0.5394 - resident1_accuracy: 0.9157 - resident1_loss: 0.1816 - resident2_accuracy: 0.9063 - resident2_loss: 0.3495 - val_loss: 0.5446 - val_resident1_accuracy: 0.9446 - val_resident1_loss: 0.1461 - val_resident2_accuracy: 0.9353 - val_resident2_loss: 0.3906\n",
      "Epoch 6/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 8ms/step - loss: 0.5387 - resident1_accuracy: 0.9158 - resident1_loss: 0.1815 - resident2_accuracy: 0.9061 - resident2_loss: 0.3493 - val_loss: 0.5525 - val_resident1_accuracy: 0.9455 - val_resident1_loss: 0.1439 - val_resident2_accuracy: 0.9344 - val_resident2_loss: 0.4010\n",
      "Epoch 7/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 7ms/step - loss: 0.5379 - resident1_accuracy: 0.9157 - resident1_loss: 0.1819 - resident2_accuracy: 0.9065 - resident2_loss: 0.3485 - val_loss: 0.5682 - val_resident1_accuracy: 0.9470 - val_resident1_loss: 0.1466 - val_resident2_accuracy: 0.9322 - val_resident2_loss: 0.4144\n",
      "Epoch 8/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 7ms/step - loss: 0.5373 - resident1_accuracy: 0.9156 - resident1_loss: 0.1817 - resident2_accuracy: 0.9066 - resident2_loss: 0.3484 - val_loss: 0.5715 - val_resident1_accuracy: 0.9450 - val_resident1_loss: 0.1461 - val_resident2_accuracy: 0.9311 - val_resident2_loss: 0.4187\n",
      "Epoch 9/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 7ms/step - loss: 0.5356 - resident1_accuracy: 0.9158 - resident1_loss: 0.1809 - resident2_accuracy: 0.9066 - resident2_loss: 0.3477 - val_loss: 0.5675 - val_resident1_accuracy: 0.9475 - val_resident1_loss: 0.1432 - val_resident2_accuracy: 0.9342 - val_resident2_loss: 0.4172\n",
      "Epoch 10/10\n",
      "\u001b[1m32400/32400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7ms/step - loss: 0.5360 - resident1_accuracy: 0.9157 - resident1_loss: 0.1812 - resident2_accuracy: 0.9066 - resident2_loss: 0.3479 - val_loss: 0.5708 - val_resident1_accuracy: 0.9473 - val_resident1_loss: 0.1396 - val_resident2_accuracy: 0.9344 - val_resident2_loss: 0.4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24e3e08cbb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dropout, Dense\n",
    "\n",
    "# CNN + LSTM Model\n",
    "inputs = Input(shape=(X_train.shape[1], 1))  # Based on preprocessing reshape\n",
    "\n",
    "# CNN Layers\n",
    "Layer = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "Layer = MaxPooling1D(pool_size=2)(Layer)\n",
    "\n",
    "# LSTM Layer (Sequence processing)\n",
    "Layer = LSTM(70)(Layer)  # LSTM layer to capture the sequence dependencies\n",
    "Layer = Dropout(0.1)(Layer)  # Dropout layer for regularization\n",
    "\n",
    "# Dense Layer\n",
    "Layer = Dense(100, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(Layer)\n",
    "\n",
    "# Output Layer for Resident 1 and Resident 2\n",
    "out_layerR1 = Dense(27, activation='softmax', name='resident1')(Layer)\n",
    "out_layerR2 = Dense(27, activation='softmax', name='resident2')(Layer)\n",
    "\n",
    "# Define the Model\n",
    "cnn_lstm_model = Model(inputs=inputs, outputs=[out_layerR1, out_layerR2])\n",
    "\n",
    "# Compile the Model\n",
    "cnn_lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'resident1': 'categorical_crossentropy', 'resident2': 'categorical_crossentropy'},\n",
    "    loss_weights={'resident1': 0.5, 'resident2': 1.0},\n",
    "    metrics={'resident1': 'accuracy', 'resident2': 'accuracy'}\n",
    ")\n",
    "\n",
    "# Model Summary\n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "# Train the CNN+LSTM model for 2 Residents\n",
    "cnn_lstm_model.fit(\n",
    "    X_train, {'resident1': y_train_res1, 'resident2': y_train_res2}, \n",
    "    epochs=10, batch_size=64,        #   86400 * 24  = 2,073,600 / 64     = 32400\n",
    "    validation_data=(X_test, {'resident1': y_test_res1, 'resident2': y_test_res2})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16200/16200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.7767 - resident1_accuracy: 0.9542 - resident1_loss: 0.1245 - resident2_accuracy: 0.8746 - resident2_loss: 0.6440\n",
      "Resident 1 - Accuracy: 94.73 %\n",
      "Resident 2 - Accuracy: 93.44 %\n",
      "Average Accuracy: 93.87 %\n",
      "Computation Time (seconds): 38.55\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation = cnn_lstm_model.evaluate(\n",
    "    X_test, \n",
    "    {'resident1': y_test_res1, 'resident2': y_test_res2}, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "computation_time = end_time - start_time  # Time in seconds\n",
    "\n",
    "# Extract the accuracies\n",
    "accuracy_res1 = evaluation[3] * 100  # Convert to percentage\n",
    "accuracy_res2 = evaluation[4] * 100  # Convert to percentage\n",
    "\n",
    "# Loss weights for calculating the weighted average accuracy\n",
    "loss_weight_res1 = 0.5\n",
    "loss_weight_res2 = 1.0\n",
    "\n",
    "# Calculate the average accuracy (weighted)\n",
    "average_accuracy = (\n",
    "    (accuracy_res1 * loss_weight_res1) + (accuracy_res2 * loss_weight_res2)\n",
    ") / (loss_weight_res1 + loss_weight_res2)\n",
    "\n",
    "# Print the results in the desired format\n",
    "print(f\"Resident 1 - Accuracy: {accuracy_res1:.2f} %\")\n",
    "print(f\"Resident 2 - Accuracy: {accuracy_res2:.2f} %\")\n",
    "print(f\"Average Accuracy: {average_accuracy:.2f} %\")\n",
    "print(f\"Computation Time (seconds): {computation_time:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16200/16200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step\n",
      "\u001b[1m16200/16200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuba\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resident 1 - Precision: 94.59%, Recall: 95.05%, F1 Score: 94.66%\n",
      "Resident 2 - Precision: 94.05%, Recall: 96.06%, F1 Score: 94.79%\n",
      "Model saved as cnn_lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Predict the results on the test data\n",
    "y_pred_res1 = cnn_lstm_model.predict(X_test)[0]  # Predictions for Resident 1\n",
    "y_pred_res2 = cnn_lstm_model.predict(X_test)[1]  # Predictions for Resident 2\n",
    "\n",
    "# Convert the predicted values (from one-hot encoding) to class labels\n",
    "y_pred_res1 = np.argmax(y_pred_res1, axis=1)\n",
    "y_pred_res2 = np.argmax(y_pred_res2, axis=1)\n",
    "\n",
    "# Convert the true labels from one-hot encoding to class labels\n",
    "y_test_res1 = np.argmax(y_test_res1, axis=1)\n",
    "y_test_res2 = np.argmax(y_test_res2, axis=1)\n",
    "\n",
    "# Calculate metrics for Resident 1\n",
    "precision_res1 = precision_score(y_test_res1, y_pred_res1, average='weighted', labels=np.unique(y_pred_res1)) * 100\n",
    "recall_res1 = recall_score(y_test_res1, y_pred_res1, average='weighted', labels=np.unique(y_pred_res1)) * 100\n",
    "f1_res1 = f1_score(y_test_res1, y_pred_res1, average='weighted', labels=np.unique(y_pred_res1)) * 100\n",
    "\n",
    "# Calculate metrics for Resident 2\n",
    "precision_res2 = precision_score(y_test_res2, y_pred_res2, average='weighted', labels=np.unique(y_pred_res2)) * 100\n",
    "recall_res2 = recall_score(y_test_res2, y_pred_res2, average='weighted', labels=np.unique(y_pred_res2)) * 100\n",
    "f1_res2 = f1_score(y_test_res2, y_pred_res2, average='weighted', labels=np.unique(y_pred_res2)) * 100\n",
    "\n",
    "# Print the results in percentage\n",
    "print(f\"Resident 1 - Precision: {precision_res1:.2f}%, Recall: {recall_res1:.2f}%, F1 Score: {f1_res1:.2f}%\")\n",
    "print(f\"Resident 2 - Precision: {precision_res2:.2f}%, Recall: {recall_res2:.2f}%, F1 Score: {f1_res2:.2f}%\")\n",
    "\n",
    "# Save the model after training\n",
    "cnn_lstm_model.save('cnn_lstm_model.h5')  # Save the model to a file\n",
    "print(\"Model saved as cnn_lstm_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "| Type of Layers   |   Number of Layers |\n",
      "+==================+====================+\n",
      "| InputLayer       |                  1 |\n",
      "+------------------+--------------------+\n",
      "| Conv1D           |                  1 |\n",
      "+------------------+--------------------+\n",
      "| MaxPooling1D     |                  1 |\n",
      "+------------------+--------------------+\n",
      "| LSTM             |                  1 |\n",
      "+------------------+--------------------+\n",
      "| Dropout          |                  1 |\n",
      "+------------------+--------------------+\n",
      "| Dense            |                  3 |\n",
      "+------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Get the layers from the model\n",
    "layers = [layer.__class__.__name__ for layer in cnn_lstm_model.layers]\n",
    "\n",
    "# Count the number of each type of layer\n",
    "layer_counts = Counter(layers)\n",
    "\n",
    "# Prepare the data for the table\n",
    "table_data = [[\"Type of Layers\", \"Number of Layers\"]]\n",
    "table_data.extend([[layer_type, count] for layer_type, count in layer_counts.items()])\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
